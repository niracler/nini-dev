# 页 6：Token 与 Context Window（🔴 重点）

## 页面内容摘要

```
# Token 与 Context Window — LLM 的两个核心概念
🔴 重点

左栏 - Token：
- 刻度尺：200(函数) → 1K(页) → 5K(文件) → 200K(书)
- 中文 ≈ 1.4 tokens/字，英文 ≈ 1.2 tokens/词
- 价格表：GPT-5.2 $1.75/$14, Claude Opus 4.5 $5/$25, DeepSeek V3.2 $0.28/$0.42

右栏 [v-click] - Context Window：
- GPT-3 的 2048 tokens 可视化
- 对比条：GPT-3 (2K) vs Claude 4 (200K)

[v-click] 两张图片（详细可视化）

脚注：OpenAI Tokenizer, Jay Alammar 可视化
```

## 6 问分析

### 1. 如何讲

- **时长**：~4 分钟
- **节奏**：
  - 先讲左栏 Token：「Token 是计费单位，看这个刻度尺...」
  - 讲价格表：「不同模型价格差异很大，DeepSeek 比 GPT-5.2 便宜 6-33 倍」
  - Click 1：揭示 Context Window，讲 GPT-3 的 2K 限制
  - Click 2-3：展示可视化图片，加深理解
- **过渡语**：
  - 开场：「上一页提到 Token 和 Context Window，这页展开讲一下。」
  - 结束：「从 2K 到 200K，Context Window 增长了 100 倍——这是后面讲 Agent 的基础。接下来看 Copilot 是怎么用这些能力的。」
- **核心记忆点**：**Token 是计费单位，Context Window 决定 AI 能"看"多少**

### 2. 为何要懂

- **痛点**：不理解 Token 就不知道成本从哪来，不理解 Context Window 就不知道为什么 AI 会"忘事"
- **价值**：理解这两个概念是评估 AI 工具能力和成本的基础
- **与听众的关联**：知道为什么有时候 AI 回答变差了（Context 溢出了）
- **重要程度**：🔴 必须懂

### 3. 演示策略

- **需要演示**：否（页面已有足够可视化）
- **备用**：如果有人好奇，可以打开 OpenAI Tokenizer 网页演示

### 4. 可能问题

**同事视角：**

| 问题 | 准备的回答 |
| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| DeepSeek 这么便宜，为什么不都用它？ | 便宜但能力有差异，复杂任务 Claude/GPT 更强。不同场景选不同模型 |
| 200K 是多少？ | 约 15 万字，一本中等长度的书 |
| 超过 Context Window 会怎样？ | 早期内容会被"遗忘"或截断，AI 看不到了 |
| AI 公司怎么赚钱？成本在哪？ | 成本分两部分：**训练成本**（一次性，如 GPT-4 据说花了上亿美元）和**推理成本**（持续的，每次调用都要算力，就是 Token 费）。目前主流 AI 公司都在亏损阶段 |

**老板视角：**

| 问题 | 准备的回答 |
| ---------------------------- | -------------------------------------------------------------------------- |
| 我们用哪个模型？成本多少？ | 看具体场景。DeepSeek 适合简单任务，复杂任务用 Claude/GPT。成本取决于使用量 |
| 我们用 AI 的成本结构是什么？ | 我们付的是推理成本（按 Token 计费）。训练成本是 OpenAI/Anthropic 承担的 |

### 5. 取舍逻辑

| 没讲的内容 | 取舍理由 |
| ---------------------------- | ---------------------------------------- |
| Tokenizer 算法细节（BPE 等） | 📚 太深入，知道"大概 1-2 token/字"就够了 |
| 各模型详细对比 | ⏱️ 时间限制，给出代表性的就行 |
| Context Window 扩展技术 | 🔄 后面会讲到（RAG、滑动窗口等） |
| 训练成本 vs 推理成本详细展开 | ⏱️ 时间限制，口头补充即可 |

**如果被问到怎么答**：「Tokenizer 的具体算法可以看脚注链接，今天重点是理解概念。」

### 6. 观点/事实区分

| 内容 | 类型 | 来源/依据 | 不确定性 |
| ------------------- | -------- | -------------------- | ---------------- |
| Token 价格 | 事实 | 官方定价（可能过时） | 中（价格常变动） |
| 1.4 tokens/中文字 | 事实 | Tokenizer 测试 | 低 |
| Context Window 对比 | 事实 | 官方文档 | 低 |
| AI 公司都在亏损 | 共识观点 | 行业报道 | 中 |

**讲解时注意**：价格可能已经变了，强调"这是截止到我准备材料时的价格"
