# 页 5：GPT-3 发布（🔴 重点）

## 页面内容摘要

```
# 2020.5: GPT-3 发布 — 1750 亿参数，证明「规模」带来质变
🔴 重点

左栏概念卡片：
- Token（词元）：计费单位，100-300 tokens ≈ 一个函数
- Next-Token Prediction：本质是「预测下一个词」→ 会胡说八道
- Context Window（上下文窗口）：GPT-3 仅 2K

右栏 [v-click]：
- 文本补全示例（不是对话）
- GPT-3 的局限：❌ 无状态、无记忆、无网络、无工具、纯文字、2K

脚注：OpenAI 论文
```

## 6 问分析

### 1. 如何讲

- **时长**：~4 分钟
- **节奏**：
  - 先讲 Mermaid 图：「GPT-3 是一个文本补全模型——给它输入，它预测下一个词」
  - 逐个解释三个概念卡片（Token、Next-Token、Context Window）
  - Click：展示文本补全示例 + 六个局限
- **过渡语**：
  - 开场：「AI 编程的历史，我们从 2020 年的 GPT-3 讲起。」
  - 结束：「这些局限，后面的技术都是在一个一个解决它们——先来深入理解 Token 和 Context Window。」
- **核心记忆点**：**GPT-3 是"文本补全"，不是"对话"，它有很多局限**

### 2. 为何要懂

- **痛点**：很多人以为 AI 是"理解"人类语言，其实只是"预测下一个词"
- **价值**：理解 Next-Token Prediction 是理解 AI 幻觉、局限的基础
- **与听众的关联**：知道为什么 AI 会"胡说八道"，就不会盲目信任
- **重要程度**：🔴 必须懂（这是后续所有内容的基础）

### 3. 演示策略

- **需要演示**：否（页面有示例，不需要现场演示）
- **备用**：如果有人问"能演示一下吗"，可以在 Claude Code 里输入半句话让它补全

### 4. 可能问题

**同事视角：**

| 问题 | 准备的回答 |
| ------------------------ | ------------------------------------------------------------------------- |
| 什么是 Token？ | 简单理解：1 个英文单词 ≈ 1 token，1 个中文字 ≈ 2 token。API 按 token 计费 |
| 为什么说它会"胡说八道"？ | 因为它只是预测"最可能的下一个词"，不是真的"理解"——后面讲幻觉会详细解释 |
| 2K 是什么意思？ | 2000 个 token，大约 1500 个汉字或 1 页半文档 |

**老板视角：**

| 问题 | 准备的回答 |
| ------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2020 年的东西为什么要讲？ | 理解起点才能理解进化，GPT-3 的局限正是后续技术要解决的问题 |
| 为什么从 GPT-3 讲起，不从更早的开始？ | 从 word2vec、BERT 讲起一下午都推进不了进度。GPT-3 是"麻雀虽小五脏俱全"——Token、Context Window、Next-Token Prediction 这些核心概念它都有，是理解后面所有 LLM 玩法的基础 |

### 5. 取舍逻辑

| 没讲的内容 | 取舍理由 |
| ------------------------- | ----------------------------------------------- |
| word2vec、BERT 等早期模型 | ⏱️ 一下午都推进不了进度，GPT-3 已经"五脏俱全" |
| GPT-1、GPT-2 | ⏱️ GPT-3 是里程碑，之前的对理解当前工具帮助有限 |
| 训练细节（预训练、微调） | 📚 太深入，扫盲不需要 |

**如果被问到怎么答**：「GPT-3 虽然是 2020 年的，但它包含了我们需要理解的所有核心概念——Token、Context Window、Next-Token Prediction。后面的模型都是在这个基础上演进的。」

### 6. 观点/事实区分

| 内容 | 类型 | 来源/依据 | 不确定性 |
| ------------------------------ | -------- | ------------ | -------- |
| 1750 亿参数 | 事实 | OpenAI 论文 | 低 |
| "规模带来质变" | 共识观点 | 行业共识 | 低 |
| Next-Token Prediction 导致幻觉 | 事实 | LLM 工作原理 | 低 |
| Token 计费估算 | 事实 | API 定价 | 低 |

**讲解时注意**：无特别争议
